# Intro-to-EDA
Steps in Exploratory Data Analysis (EDA) EDA is performed in a structured manner to extract insights. The general steps are: 
1Data Cleaning &amp; Preprocessing
2.Statistical Analysis 
3.Univariate Analysis &amp; Visualization 
4.Bivariate Analysis &amp; Visualization 
5.Interpretation of Results



1. UNDERSTANDING DATA .ipynb: This Jupyter notebook introduces basic data understanding techniques, including summary statistics, initial data exploration, and preliminary visualizations. It sets up the foundation for all subsequent EDA steps.

DC1 Dealing with Missing Values .ipynb: This notebook addresses data cleaning, outlining methods for detecting and processing missing values. It might include imputation strategies or removal techniques for handling incomplete datasets.

DC_2_Dealing_with_Duplicate_Data.ipynb: Focuses on identifying and removing duplicate records, which helps ensure the integrity of analysis and prevents biased results.

DC_3_Outliers_Removal_using_Z_Score.ipynb: Provides a detailed workflow for outlier detection and removal using the Z-score statistical method, including how to threshold and filter out extreme values.

DC_4_Outlier_Removal_using_IQR_.ipynb: The notebook targets outlier removal using the Interquartile Range (IQR) method, explaining step-wise calculations and application to common datasets.

DC_5_Outlier_Removal_using_Percentile.ipynb: Demonstrates outlier removal by applying percentile-based filtering, a more flexible approach that can adapt to non-standard data distributions.

README.md: Contains an overview of the repository and structured steps for performing effective EDA: starting with data cleaning and preprocessing, continuing through statistical and visualization methods (including univariate and bivariate analysis), and ending with the interpretation of results.

General Structure and Purpose:

The repository is organized to guide a user through the complete EDA process in a stepwise manner. Each notebook addresses a specific data cleaning or analysis technique, providing clear, modular code and explanations.

The process makes extensive use of Python and the Jupyter Notebook format for reproducibility and interactive analysis.

Ideal for students or beginners, the repo emphasizes practical workflows for real-world datasets, helping users apply EDA methods systematically for data science projects.

This repo is especially useful for learning hands-on data preprocessing and cleaningâ€”crucial steps before statistical analysis and machine learning modeling.
